{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설정이 필요한 부분)\n",
    "1. service = Service('/Users/myo/development/chromedriver')  # chromedriver 경로를 지정해주세요 -> 컴퓨터의 크롬드라이브 경로를 찾아서 설정해주기. 아마 크롬드라이버를 다운 받아야 할듯.\n",
    "2. input_file = '/Users/myo/Desktop/Kangs/interv_sr_list.csv' 부분과 output_file = '/Users/myo/Desktop/Kangs/picos_good.csv' 부분의 파일들 경로 지정해두기. 참고로 이 ipynb 파일은 맥북 기준이고, 윈도우는 맥북과 다르게 경로 설정이 \\ 역슬래시임. interv_sr_list는 논문 제목을 가져올 csv 파일이고 얘는 github에 올라와 있음, picos_good은 추출한 피코 정보를 기입할 새로운 파일이름임. Picos_good.csv 파일 이름은 마음대로 지정해도 됨\n",
    "3. 처리할 논문 범위 설정\n",
    "    start_index = n - 1  # 데이터프레임 인덱스는 0부터 시작\n",
    "    end_index = m -> 컴퓨터를 나눠서 돌릴 것이기 때문에 n, m 숫자 지정(원하는 논문이 예를 들어 2001번부터 2200까지면 n=2001, m=2200으로 n, m만 바꾸면 되게 코딩되어 있음)\n",
    "4. 오류가 날 수 있는 포인트 : chrome driver 및 파일들 경로 지정 오류, chrome과 Chromedriver 버전 안맞는 오류.\n",
    "5. 혹시라도 오류 생기면 GPT한테 물어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "\n",
    "def get_first_paper_link(driver, title):\n",
    "    # Cochrane Library 검색 페이지로 이동\n",
    "    search_url = \"https://www.cochranelibrary.com/search\"\n",
    "    driver.get(search_url)\n",
    "\n",
    "    # 검색창 찾기 및 논문 제목 입력\n",
    "    search_box = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"searchText\"))\n",
    "    )\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(title)\n",
    "    search_box.send_keys(\"\\n\")\n",
    "\n",
    "    # 첫 번째 검색 결과의 링크 추출\n",
    "    first_result = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \".search-results-item .result-title a\"))\n",
    "    )\n",
    "    paper_link = first_result.get_attribute('href')\n",
    "    \n",
    "    return paper_link\n",
    "\n",
    "def extract_pico(url):\n",
    "    # Selenium 설정\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # GUI 없이 실행\n",
    "    service = Service('/Users/myo/development/chromedriver')  # chromedriver 경로를 지정해주세요\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    # PICO 섹션이 로드될 때까지 대기\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    wait.until(EC.presence_of_element_located((By.ID, \"pico\")))\n",
    "    \n",
    "    # 페이지 스크롤\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)  # 스크롤 후 콘텐츠 로드를 위한 대기\n",
    "\n",
    "    # 페이지 소스 가져오기\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    pico = {}\n",
    "    pico_section = soup.find('section', class_='pico-section', id='pico')\n",
    "    \n",
    "    if pico_section:\n",
    "        for column in pico_section.find_all('div', class_='pico-column'):\n",
    "            pico_type = column['class'][1]  # Population, Intervention, Comparison, Outcome\n",
    "            terms = [a.text.strip() for a in column.find_all('a')]\n",
    "            pico[pico_type] = terms\n",
    "\n",
    "    driver.quit()\n",
    "    return pico\n",
    "\n",
    "def process_papers(start_index, end_index, titles_df, output_file):\n",
    "    # Selenium 설정\n",
    "    chrome_options = Options()\n",
    "    service = Service('/Users/myo/development/chromedriver')  # chromedriver 경로를 지정해주세요\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    pico_data = []\n",
    "\n",
    "    # 지정된 범위의 논문에 대해 링크 추출 및 PICO 정보 추출\n",
    "    for index in range(start_index, end_index):\n",
    "        if index >= len(titles_df):\n",
    "            break\n",
    "        \n",
    "        row = titles_df.iloc[index]\n",
    "        title = row['Title']\n",
    "        year_issue = f\"{row['Year']}-{row['Issue']}\"\n",
    "        print(f\"Processing {index+1}/{len(titles_df)}: {title}\")\n",
    "\n",
    "        try:\n",
    "            # 논문의 첫 번째 링크 추출\n",
    "            paper_link = get_first_paper_link(driver, title)\n",
    "            print(f\"Found paper link: {paper_link}\")\n",
    "\n",
    "            # PICO 정보 추출\n",
    "            pico_info = extract_pico(paper_link)\n",
    "            pico_info[\"No.\"] = index + 1\n",
    "            pico_info[\"Year-Issue\"] = year_issue\n",
    "            pico_info[\"Title\"] = title  # PICO 정보에 제목 추가\n",
    "            pico_data.append(pico_info)\n",
    "            print(f\"PICO data for {title}: {pico_info}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing title: {title}, error: {e}\")\n",
    "            # 오류 발생 시, 제목만 저장하고 나머지는 공백으로 처리\n",
    "            pico_data.append({\"No.\": index + 1, \"Year-Issue\": year_issue, \"Title\": title, \"Population\": \"\", \"Intervention\": \"\", \"Comparison\": \"\", \"Outcome\": \"\"})\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # 결과를 DataFrame으로 변환\n",
    "    df = pd.DataFrame(pico_data, columns=[\"No.\", \"Year-Issue\", \"Title\", \"Population\", \"Intervention\", \"Comparison\", \"Outcome\"])\n",
    "\n",
    "    # 기존 CSV 파일에 추가\n",
    "    if os.path.exists(output_file):\n",
    "        # 파일의 끝에 데이터를 추가\n",
    "        with open(output_file, 'a') as f:\n",
    "            df.to_csv(f, header=False, index=False)\n",
    "    else:\n",
    "        # 파일이 없으면 새로 작성\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Saved PICO data to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    # CSV 파일에서 논문 제목 읽기\n",
    "    input_file = '/Users/myo/Desktop/Kangs/interv_sr_list.csv'\n",
    "    titles_df = pd.read_csv(input_file)\n",
    "\n",
    "    # 출력 파일 설정\n",
    "    output_file = '/Users/myo/Desktop/Kangs/picos_good.csv'\n",
    "\n",
    "    # 특정 논문 범위를 설정\n",
    "    n = int(input(\"Start index (n): \"))  # 시작 논문 번호\n",
    "    m = int(input(\"End index (m): \"))    # 종료 논문 번호\n",
    "\n",
    "    if n < 1 or m > len(titles_df) or n > m:\n",
    "        print(\"Invalid range. Please check the indices.\")\n",
    "        return\n",
    "\n",
    "    # 처리할 논문 범위 설정\n",
    "    start_index = n - 1  # 데이터프레임 인덱스는 0부터 시작\n",
    "    end_index = m\n",
    "\n",
    "    # 논문 처리\n",
    "    process_papers(start_index, end_index, titles_df, output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
